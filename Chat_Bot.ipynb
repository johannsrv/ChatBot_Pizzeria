{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las librerias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "import random \n",
    "import spacy\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import expand_dims\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "nlp= spacy.load('es_core_news_lg') # carga un modelo de lenguaje de spaCy en la variable nlp. El modelo 'en_core_web_sm' es un modelo de lenguaje en Español\n",
    "\n",
    "warnings.filterwarnings('ignore') # suprime todos los mensajes de advertencia que se generan durante la ejecución del código. Esto puede ser útil si estás ejecutando un código que genera muchos mensajes de advertencia que no son relevantes para tu tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leemos y Procesamos nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(line):\n",
    "    re.sub(r'[^a-záéíóúñüÁÉÍÓÚÑÜ0-9,.!?;]', \" \", line)\n",
    "    #line= re.sub(r'[]+',' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer datos\n",
    "\n",
    "with open('intentos_pizzas.json','rb') as file:\n",
    "    data= json.load(file)\n",
    "    # obtener texto y títulos de intención a partir de datos json\n",
    "    inputs, targets= [], []\n",
    "    cls= []\n",
    "    intent_doc= {}\n",
    "\n",
    "    for i in data['intents']:\n",
    "        if i['intent'] not in cls:\n",
    "            cls.append(i['intent'])\n",
    "        \n",
    "        if i['intent'] not in intent_doc:\n",
    "            intent_doc[i['intent']]= []\n",
    "        \n",
    "        for text in i['text']:\n",
    "            inputs.append(pre_processing(text))\n",
    "            targets.append(i['intent'])\n",
    "        \n",
    "        for response in i['responses']:\n",
    "            intent_doc[i['intent']].append(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hola', 'Buenas', 'Hola, ¿cómo estás?', 'Buenas tardes', 'Buenas noches', 'Hola tienes servicio', 'tienes comida', 'Tienes servicio', 'Quiero ver el menú', 'Que tienes de comer', 'Qué opciones tienen?', '¿Puedes mostrarme la carta?', 'Menú por favor', '¿Qué puedo ordenar?', 'Necesito ver las opciones', 'que tienes de comer', 'Tienes carta', 'Que comida tienes', 'Que me ofreces', 'Que tienes de comida', 'Que perros tienes', 'De que tienes los perros', 'cuales perros me ofreces', 'como cuales perros tienes', 'Que tipo de perros tienes', 'Que salchipapas tienes', 'De que tienes las salchipapa', 'cuales salchipapa me ofreces', 'como cuales salchipapa tienes', 'Que tipo de salchipapa tienes', 'Que hamburguesas tienes', 'De que tienes las hamburguesas', 'cuales hamburguesas me ofreces', 'como cuales hamburguesas tienes', 'Que tipo de hamburguesas tienes', 'Quiero ordenar una Pizza Megafamiliar y dos porciones de pizzas', 'Me gustaría una Pizza Familiar y 4 pizza por porcion', 'Quiero una Pizza Familiar', 'Voy a ordenar una Pizza porcion ', 'Puedes traerme 3 Pizza Mega familiar y una Pizza fmiliar', 'Deseo ordenar una Pizza mega familar', 'Puedes traerme tres Pizza Mega familiar y cinco Pizza fmiliar', 'Voy a ordenar 2 Pizza porcion ', 'Sí, es correcto', 'Sí, confirmo', 'Todo está bien', 'Así es', 'Correcto', 'Sí, así es', 'si', 'esta todo bien', 'si señor', 'No, no es correcto', 'Quiero agregar/quitar algo', 'Deseo cambiar mi pedido', 'Que sabores de pizzas tienes', 'que tipo de pizza tienes', 'Que pizzas me ofrece', 'De que tiene las pizzas', 'Cuales pizzas tienes', '¿Qué ingredientes tiene la pizza criolla?', 'Dime los ingredientes de la pizza criolla', 'que trae la pizza criolla', 'Que tra la criolla', 'Que trae la pizza de criolla', '¿Qué ingredientes tiene la pizza poolo con champiñon?', 'Dime los ingredientes de la pizza pollo con champiñon', 'Que tra la de pollo con pello con champiñon', 'Que trae la pizza de pollo con champiñon', '¿Qué ingredientes tiene la pizza de pollo', 'Dime los ingredientes de la pizza de pollo', 'Que tra la de pollo con pello', 'Que trae la pizza de pollo', '¿Qué ingredientes tiene la pizza carnes?', 'Dime los ingredientes de la pizza carnes', 'Que tra la de carnes', 'Que trae la pizza de carnes', '¿Cuántas porciones tiene la pizza Mega?', 'Dime el número de porciones de la pizza Mega', '¿Cuántas porciones tiene la pizza Familiar?', 'Dime el número de porciones de la pizza Familiar', 'Mi dirección es Torre 5 Quintas de modelia 1', 'Vivo en la calle 456', 'La dirección es quintas 2 casa 25', 'Estoy en el apartamento 101 de quintas 3', 'Mi dirección para la entrega es Calle Secundaria 246', 'La dirección para el envío es Calle Principal, Edificio 3, Apartamento 5']\n",
      "['Saludo', 'Saludo', 'Saludo', 'Saludo', 'Saludo', 'Saludo', 'Saludo', 'Saludo', 'PedidoCarta', 'PedidoCarta', 'PedidoCarta', 'PedidoCarta', 'PedidoCarta', 'PedidoCarta', 'PedidoCarta', 'PedidoCarta', 'PedidoCarta', 'PedidoCarta', 'PedidoCarta', 'PedidoCarta', 'Clasedeperros', 'Clasedeperros', 'Clasedeperros', 'Clasedeperros', 'Clasedeperros', 'Clasedesalchipapa', 'Clasedesalchipapa', 'Clasedesalchipapa', 'Clasedesalchipapa', 'Clasedesalchipapa', 'ClasedeHamburguesas', 'ClasedeHamburguesas', 'ClasedeHamburguesas', 'ClasedeHamburguesas', 'ClasedeHamburguesas', 'RealizarPedido', 'RealizarPedido', 'RealizarPedido', 'RealizarPedido', 'RealizarPedido', 'RealizarPedido', 'RealizarPedido', 'RealizarPedido', 'ConfirmarPedido', 'ConfirmarPedido', 'ConfirmarPedido', 'ConfirmarPedido', 'ConfirmarPedido', 'ConfirmarPedido', 'ConfirmarPedido', 'ConfirmarPedido', 'ConfirmarPedido', 'AgregarQuitarPedido', 'AgregarQuitarPedido', 'AgregarQuitarPedido', 'IngredientesPizza', 'IngredientesPizza', 'IngredientesPizza', 'IngredientesPizza', 'IngredientesPizza', 'IngredientesEspecificosCriolla', 'IngredientesEspecificosCriolla', 'IngredientesEspecificosCriolla', 'IngredientesEspecificosCriolla', 'IngredientesEspecificosCriolla', 'IngredientesEspecificosPollo', 'IngredientesEspecificosPollo', 'IngredientesEspecificosPollo', 'IngredientesEspecificosPollo', 'IngredientesEspecificosPollo', 'IngredientesEspecificosPollo', 'IngredientesEspecificosPollo', 'IngredientesEspecificosPollo', 'IngredientesEspecificoscarnes', 'IngredientesEspecificoscarnes', 'IngredientesEspecificoscarnes', 'IngredientesEspecificoscarnes', 'PorcionesPizzaMG', 'PorcionesPizzaMG', 'PorcionesPizzaF', 'PorcionesPizzaF', 'ProporcionarDireccion', 'ProporcionarDireccion', 'ProporcionarDireccion', 'ProporcionarDireccion', 'ProporcionarDireccion', 'ProporcionarDireccion']\n",
      "['Saludo', 'PedidoCarta', 'Clasedeperros', 'Clasedesalchipapa', 'ClasedeHamburguesas', 'RealizarPedido', 'ConfirmarPedido', 'AgregarQuitarPedido', 'IngredientesPizza', 'IngredientesEspecificosCriolla', 'IngredientesEspecificosPollo', 'IngredientesEspecificoscarnes', 'PorcionesPizzaMG', 'PorcionesPizzaF', 'ProporcionarDireccion']\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(targets)\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cr_cat_targe(targets):\n",
    "    word= {}\n",
    "    cat_t= []\n",
    "    counter= 0\n",
    "    \n",
    "    for trg in targets:\n",
    "        if trg not in word:\n",
    "            word[trg]= counter\n",
    "            counter+=1\n",
    "        cat_t.append(word[trg])\n",
    "        \n",
    "    cat_tensor= to_categorical(cat_t, num_classes=len(word), dtype='int32')\n",
    "    return cat_tensor, dict((v,k) for k,v in word.items())\n",
    "\n",
    "target_tensor, target_indx_word= cr_cat_targe(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Saludo', 1: 'PedidoCarta', 2: 'Clasedeperros', 3: 'Clasedesalchipapa', 4: 'ClasedeHamburguesas', 5: 'RealizarPedido', 6: 'ConfirmarPedido', 7: 'AgregarQuitarPedido', 8: 'IngredientesPizza', 9: 'IngredientesEspecificosCriolla', 10: 'IngredientesEspecificosPollo', 11: 'IngredientesEspecificoscarnes', 12: 'PorcionesPizzaMG', 13: 'PorcionesPizzaF', 14: 'ProporcionarDireccion'}\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(target_indx_word)\n",
    "print(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_data(inp_list):\n",
    "    tokenizer= Tokenizer(filters='', oov_token='<unk>')\n",
    "    tokenizer.fit_on_texts(inp_list)\n",
    "    inp_seq= tokenizer.texts_to_sequences(inp_list)\n",
    "    \n",
    "    # Agregando padding \n",
    "    inp_seq= pad_sequences(inp_seq, padding='pre')\n",
    "    return tokenizer, inp_seq\n",
    "\n",
    "tokenizer, inp_tensor= token_data(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0   0  47]\n",
      " [  0   0   0 ...   0   0  36]\n",
      " [  0   0   0 ...  73  74  75]\n",
      " ...\n",
      " [  0   0   0 ...   2  45  58]\n",
      " [  0   0   0 ...  46 124 125]\n",
      " [  5  35  72 ... 129  71  69]]\n"
     ]
    }
   ],
   "source": [
    "print(inp_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos nuestra red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramestros de nuestros modelo \n",
    "epochs= 50\n",
    "vocab_size= len(tokenizer.word_index)+1\n",
    "embed_dim= 512\n",
    "units= 120\n",
    "target_len= target_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo \n",
    "modelo= Sequential([\n",
    "    Embedding(vocab_size, embed_dim),\n",
    "    Bidirectional(LSTM(units, dropout=0.2)),\n",
    "    Dense(units, activation= 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(target_len, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 512)         66560     \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 240)               607680    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               28920     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                1815      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 704975 (2.69 MB)\n",
      "Trainable params: 704975 (2.69 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.compile(optimizer=Adam(lr= 1e-2), loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 11s 59ms/step - loss: 2.7076 - accuracy: 0.1034\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 2.6595 - accuracy: 0.1149\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 2.6100 - accuracy: 0.1379\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.5424 - accuracy: 0.1264\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.4597 - accuracy: 0.1149\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 2.4409 - accuracy: 0.1839\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.3734 - accuracy: 0.2529\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 2.2524 - accuracy: 0.3448\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.2547 - accuracy: 0.3448\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2.0558 - accuracy: 0.3563\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 1.9164 - accuracy: 0.4483\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.8749 - accuracy: 0.4943\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.7128 - accuracy: 0.4253\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.5526 - accuracy: 0.4828\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.4270 - accuracy: 0.5977\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.2605 - accuracy: 0.5862\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.2431 - accuracy: 0.5632\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 1.1234 - accuracy: 0.5402\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.9931 - accuracy: 0.6552\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.8831 - accuracy: 0.7011\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.8254 - accuracy: 0.7011\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.7803 - accuracy: 0.7701\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6483 - accuracy: 0.7931\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6512 - accuracy: 0.7701\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.5694 - accuracy: 0.8276\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5166 - accuracy: 0.8276\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.4635 - accuracy: 0.8161\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.4121 - accuracy: 0.8506\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.3791 - accuracy: 0.8851\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.2333 - accuracy: 0.9425\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1956 - accuracy: 0.9770\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1978 - accuracy: 0.9770\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.2135 - accuracy: 0.9310\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.1754 - accuracy: 0.9540\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.1777 - accuracy: 0.9655\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1227 - accuracy: 0.9770\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1423 - accuracy: 0.9540\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1544 - accuracy: 0.9655\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0618 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0806 - accuracy: 0.9885\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.1278 - accuracy: 0.9540\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1321 - accuracy: 0.9770\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.1492 - accuracy: 0.9770\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0748 - accuracy: 0.9885\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0721 - accuracy: 0.9885\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1023 - accuracy: 0.9540\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0447 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1825e3d7dd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nuestra red se dentendra en el mejor entrenamiento\n",
    "early_spot= EarlyStopping(monitor='loss', patience= 5) # EarlyStopping que espere 2 épocas sin mejora en la pérdida antes de detener el entrenamiento\n",
    "\n",
    "modelo.fit(inp_tensor, target_tensor, epochs= epochs, callbacks=[early_spot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos nuestra funcion de respuesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(sentence):\n",
    "    sent_seq= []\n",
    "    doc= nlp(repr(sentence))\n",
    "    \n",
    "    # split the input sentences into words\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.text in tokenizer.word_index:\n",
    "            sent_seq.append(tokenizer.word_index[token.text])\n",
    "            \n",
    "        else:\n",
    "            sent_seq.append(tokenizer.word_index['<unk>'])\n",
    "            \n",
    "    sent_seq= expand_dims(sent_seq, 0)\n",
    "    \n",
    "    # predict the category of input sentences\n",
    "    pred= modelo(sent_seq)\n",
    "    pred_class= np.argmax(pred.numpy(), axis=1)\n",
    "    \n",
    "    # choice a random response for predicted sentence\n",
    "    return random.choice(intent_doc[target_indx_word[pred_class[0]]]), target_indx_word[pred_class[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Entendido. Para confirmar, has pedido:\\n- <Cantidad> <Producto>\\n¿Es correcto?',\n",
       " 'RealizarPedido')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response('quiero 2 pizzas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulacion con el chat bot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Enter 'quit' to breck the loop\n"
     ]
    }
   ],
   "source": [
    "print(\"Note: Enter 'quit' to breck the loop\")\n",
    "\n",
    "while True:\n",
    "    respuesta = input('Tú: ')\n",
    "    if respuesta.lower() == 'quit':\n",
    "        break\n",
    "\n",
    "    res, typ = response(respuesta)\n",
    "    print('Bot:{}--TYPE: {}'.format(res, typ))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
